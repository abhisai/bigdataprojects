{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53cbab65-74b0-4d87-a5aa-e89f12dc3817",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_layout = \"customer_id int , customer_name string,customer_state string, Sex string, Age int, Holding_Value int,Open_Date DATE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02eaea0c-daf8-4ff9-b6da-c481e273dc61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+--------------+---+----+-------------+-------------------+\n|customer_id|   customer_name|customer_state|Sex| Age|Holding_Value|          Open_Date|\n+-----------+----------------+--------------+---+----+-------------+-------------------+\n|        2.0|  Robert Johnson|American Samoa|  F|22.0|    3558910.0|2014-01-14 10:45:14|\n|        3.0|     Tracy Smith|      Nebraska|  F|47.0|     573341.0|2003-05-08 19:21:38|\n|        4.0|    Jerry Garcia|      New York|  M|29.0|    7060981.0|2021-06-16 07:47:57|\n|        5.0| Cynthia Carroll|        Kansas|  F|46.0|    2294988.0|2005-06-30 12:52:45|\n|        6.0|     Amanda Hill|     Minnesota|  F|66.0|    8358368.0|2010-04-13 10:25:47|\n|        7.0|    David Taylor|      Oklahoma|  M|87.0|    9264052.0|1998-11-09 21:53:26|\n|        8.0|   Diana Brennan|      Colorado|  F|75.0|    7828697.0|2010-09-22 09:39:37|\n|        9.0|Jeffrey Williams|    New Mexico|  M|41.0|    8641727.0|2007-10-10 17:34:56|\n|       10.0|  Amanda Sherman|  North Dakota|  F|31.0|    2104087.0|2021-01-03 06:09:30|\n|       11.0|    James Gamble|       Florida|  M|31.0|    5536533.0|1995-04-01 09:03:04|\n+-----------+----------------+--------------+---+----+-------------+-------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "#spark = SparkSession.builder \\\n",
    "#    .appName(\"Read Excel File from DBFS\") \\\n",
    "#    .getOrCreate()\n",
    "\n",
    "# Define the path to the Excel file in DBFS\n",
    "file_path = \"dbfs:/FileStore/customers_021424.csv\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"schema\",\"customers_layout\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.show(10)\n",
    "\n",
    "# Stop the Spark session\n",
    "#spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffe5fe41-f76f-4840-b311-0d700f5cee66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Number of accounts opened in 2023 is : '340' ''Number of accounts opened in 2022 is : '336'Change in number of accounts opened between 2023 and 2022 is : '1.1904761904761905"
     ]
    }
   ],
   "source": [
    "## Get year on year open details \n",
    "df_2023 = df.where(\"YEAR(Open_Date) = 2023\")\n",
    "count_2023 = df_2023.count()\n",
    "display(\"Number of accounts opened in 2023 is : \", count_2023)\n",
    "\n",
    "df_2022 = df.where(\"YEAR(Open_Date) = 2022\")\n",
    "count_2022 = df_2022.count()\n",
    "display(\" \")\n",
    "display(\"Number of accounts opened in 2022 is : \", count_2022)\n",
    "\n",
    "#Difference from year to year \n",
    "YOY_change = (count_2023-count_2022)/count_2022*100\n",
    "display(\" Change in number of accounts opened between 2023 and 2022 is : \", YOY_change)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2beaa74-2c1c-447f-9dc3-85f228eb83bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n|customer_state|count|\n+--------------+-----+\n|          Utah|  170|\n|        Hawaii|  169|\n|     Minnesota|  174|\n|          Ohio|  168|\n|        Oregon|  170|\n|      Arkansas|  187|\n|         Texas|  190|\n|  North Dakota|  176|\n|  Pennsylvania|  148|\n|   Connecticut|  179|\n|      Nebraska|  171|\n|       Vermont|  182|\n|American Samoa|  185|\n|        Nevada|  168|\n|   Puerto Rico|  160|\n|    Washington|  187|\n|      Illinois|  180|\n|      Oklahoma|  172|\n|Virgin Islands|  187|\n|      Delaware|  189|\n+--------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "## Get State wide agreegated values \n",
    "\n",
    "state_df = df.groupBy(\"customer_state\").count()\n",
    "state_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a8412d-3780-457e-9c62-16ac3be10739",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n|Customer_State|       change_in_%|\n+--------------+------------------+\n|          Utah|-63.63636363636363|\n|        Hawaii|             -50.0|\n|     Minnesota| 33.33333333333333|\n|          Ohio|               0.0|\n|      Arkansas|             150.0|\n|        Oregon|              40.0|\n|         Texas|             125.0|\n|  North Dakota|             -50.0|\n|   Connecticut|              20.0|\n|      Nebraska|               0.0|\n|       Vermont|              12.5|\n|American Samoa|             800.0|\n|        Nevada| 33.33333333333333|\n|   Puerto Rico|               0.0|\n|    Washington|             -50.0|\n|      Illinois|               0.0|\n|      Oklahoma| 33.33333333333333|\n|Virgin Islands|              60.0|\n|      Delaware|               0.0|\n|        Alaska|-66.66666666666666|\n+--------------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "## Get State Wide change in number of accounts opened from 2023 and 2022\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "state_wide_df_2023 = df_2023.groupBy(\"Customer_State\").agg(count(\"Customer_id\").alias(\"count_of_2023\"))\n",
    "state_wide_df_2022 = df_2022.groupBy(\"Customer_State\").agg(count(\"Customer_id\").alias(\"count_of_2022\"))\n",
    "joined_df = state_wide_df_2023.join(state_wide_df_2022,\"Customer_State\",\"inner\")\n",
    "final_state_wide_change_df = joined_df.withColumn(\"change_in_%\",((joined_df.count_of_2023-joined_df.count_of_2022)/joined_df.count_of_2022)*100).select(\"Customer_State\",\"change_in_%\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48c0b6f-94bc-4940-9d0c-90f7d26b4eeb",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<command-4484988515408725>\", line 17, in <module>\n    state_df.groupBy(\"Customer_State\").agg(count(\"customer_id\").alias(\"customer_count\")).show()\nNameError: name 'count' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n    frames.append(self.format_record(r))\n  File \"/databricks/python/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n    pieces = self.included_pieces\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/databricks/python/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n    return only(\n  File \"/databricks/python/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'count' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write data state level for easy analysis\n",
    "df.write.option(\"header\", True) \\\n",
    "\t\t.partitionBy(\"Customer_State\") \\\n",
    "\t\t.mode(\"overwrite\") \\\n",
    "\t\t.csv(\"dbfs:/FileStore/state_wide_data\") \n",
    "  \n",
    "\n",
    " # Define the path to the Excel file in DBFS\n",
    "file_path = \"dbfs:/FileStore/state_wide_data/*\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "state_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"schema\",\"customers_layout\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "state_df.groupBy(\"Customer_State\").agg(count(\"customer_id\").alias(\"customer_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0a967dc-6c33-4317-8a02-cd656e0b353a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2024-02-15 00:16:47",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
